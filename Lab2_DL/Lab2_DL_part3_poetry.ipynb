{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "Lab2_DL_part3_poetry.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bl6YRN6_aVA"
      },
      "source": [
        "## Lab 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQKLswlI_aVM"
      },
      "source": [
        "### Part 3. Poetry generation\n",
        "\n",
        "Let's try to generate some poetry using RNNs. \n",
        "\n",
        "You have several choices here: \n",
        "\n",
        "* The Shakespeare sonnets, file `sonnets.txt` available in the notebook directory.\n",
        "\n",
        "* Роман в стихах \"Евгений Онегин\" Александра Сергеевича Пушкина. В предобработанном виде доступен по [ссылке](https://github.com/attatrol/data_sources/blob/master/onegin.txt).\n",
        "\n",
        "* Some other text source, if it will be approved by the course staff.\n",
        "\n",
        "Text generation can be designed in several steps:\n",
        "    \n",
        "1. Data loading.\n",
        "2. Dictionary generation.\n",
        "3. Data preprocessing.\n",
        "4. Model (neural network) training.\n",
        "5. Text generation (model evaluation).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tODT2-58_aVO"
      },
      "source": [
        "import string\n",
        "import os"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1B5Z7i1T_aVQ"
      },
      "source": [
        "### Data loading: Shakespeare"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mro3B7V9_aVR"
      },
      "source": [
        "Shakespeare sonnets are awailable at this [link](http://www.gutenberg.org/ebooks/1041?msg=welcome_stranger). In addition, they are stored in the same directory as this notebook (`sonnetes.txt`). Simple preprocessing is already done for you in the next cell: all technical info is dropped."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "7bzg_R5Q_aVS"
      },
      "source": [
        "if not os.path.exists('sonnets.txt'):\n",
        "    !wget https://raw.githubusercontent.com/girafe-ai/ml-mipt/master/homeworks_basic/Lab2_DL/sonnets.txt\n",
        "\n",
        "with open('sonnets.txt', 'r') as iofile:\n",
        "    text = iofile.readlines()\n",
        "    \n",
        "TEXT_START = 45\n",
        "TEXT_END = -368\n",
        "text = text[TEXT_START : TEXT_END]\n",
        "assert len(text) == 2616"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFOudVTU_aVV"
      },
      "source": [
        "In opposite to the in-class practice, this time we want to predict complex text. Let's reduce the complexity of the task and lowercase all the symbols.\n",
        "\n",
        "Now variable `text` is a list of strings. Join all the strings into one and lowercase it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03SE22ojBnby"
      },
      "source": [
        "text_join = ''.join(text)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGcRuBuICG9b",
        "outputId": "43a2b766-debf-4338-ef9a-53a0e353ed37"
      },
      "source": [
        "len(text_join)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100225"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6V0GTvB_aVW",
        "outputId": "bc45f5ba-d011-413a-b711-7ae046f30baa"
      },
      "source": [
        "# Join all the strings into one and lowercase it\n",
        "# Put result into variable text.\n",
        "\n",
        "# Your great code here\n",
        "text = ''.join(text).lower()\n",
        "assert len(text) == 100225, 'Are you sure you have concatenated all the strings?'\n",
        "assert not any([x in set(text) for x in string.ascii_uppercase]), 'Uppercase letters are present'\n",
        "print('OK!')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OK!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3fdgFt2_aVW"
      },
      "source": [
        "### Data loading: \"Евгений Онегин\"\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ygbl7b6G_aVY",
        "outputId": "a98711b6-74fb-457a-a775-91ee5c436dae"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/attatrol/data_sources/master/onegin.txt\n",
        "    \n",
        "with open('onegin.txt', 'r') as iofile:\n",
        "    text = iofile.readlines()\n",
        "    \n",
        "text = [x.replace('\\t\\t', '') for x in text]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Failed to set locale category LC_NUMERIC to en_RU.\n",
            "Warning: Failed to set locale category LC_TIME to en_RU.\n",
            "Warning: Failed to set locale category LC_COLLATE to en_RU.\n",
            "Warning: Failed to set locale category LC_MONETARY to en_RU.\n",
            "Warning: Failed to set locale category LC_MESSAGES to en_RU.\n",
            "--2020-05-10 19:02:32--  https://raw.githubusercontent.com/attatrol/data_sources/master/onegin.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.244.133\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.244.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 262521 (256K) [text/plain]\n",
            "Saving to: ‘onegin.txt’\n",
            "\n",
            "onegin.txt          100%[===================>] 256.37K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-05-10 19:02:33 (2.25 MB/s) - ‘onegin.txt’ saved [262521/262521]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rl862jY7_aVc"
      },
      "source": [
        "In opposite to the in-class practice, this time we want to predict complex text. Let's reduce the complexity of the task and lowercase all the symbols.\n",
        "\n",
        "Now variable `text` is a list of strings. Join all the strings into one and lowercase it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ydurbu9_aVf"
      },
      "source": [
        "# Join all the strings into one and lowercase it\n",
        "# Put result into variable text.\n",
        "\n",
        "# Your great code here\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixhLhOPR_aVg"
      },
      "source": [
        "Put all the characters, that you've seen in the text, into variable `tokens`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpkIhZj6_aVg"
      },
      "source": [
        "tokens = sorted(set(text))"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVeL_x-pDdJj",
        "outputId": "dc6e5db3-f864-4f29-ba7c-fad01b1332f5"
      },
      "source": [
        "type(tokens)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdrceDxt_aVg"
      },
      "source": [
        "Create dictionary `token_to_idx = {<char>: <index>}` and dictionary `idx_to_token = {<index>: <char>}`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "xPObjodH_aVg"
      },
      "source": [
        "# dict <index>:<char>\n",
        "# Your great code here\n",
        "token_to_idx = {char: index for (char, index) in zip(tokens, list(range(len(tokens))))}\n",
        "# dict <char>:<index>\n",
        "# Your great code here\n",
        "idx_to_char = {index: char for (char, index) in zip(tokens, list(range(len(tokens))))}"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLCHV0gm_aVh"
      },
      "source": [
        "*Comment: in this task we have only 38 different tokens, so let's use one-hot encoding.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOQy734O_aVh"
      },
      "source": [
        "### Building the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsD6RBSM_aVh"
      },
      "source": [
        "Now we want to build and train recurrent neural net which would be able to something similar to Shakespeare's poetry.\n",
        "\n",
        "Let's use vanilla RNN, similar to the one created during the lesson."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "nunT3lHm_aVi"
      },
      "source": [
        "# Your code here\n",
        "\n",
        "import torch, torch.nn as nn\n",
        "import time\n",
        "from torch.optim import lr_scheduler, Adam\n",
        "import torch.nn.functional as F\n",
        "import numpy as np"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBxduZWZeP5t"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "from torch.utils.data import DataLoader\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8nWV77pq6fy"
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    \n",
        "    def __init__(self, num_tokens=len(token_to_idx), embedding_size=100, rnn_num_units=200):\n",
        "        super(self.__class__,self).__init__()\n",
        "        self.num_units = rnn_num_units\n",
        "        \n",
        "        self.embedding = nn.Embedding(num_tokens, embedding_size)\n",
        "        self.rnn_update = nn.Linear(embedding_size + rnn_num_units, rnn_num_units)\n",
        "        self.rnn_to_logits = nn.Linear(rnn_num_units, num_tokens)\n",
        "        self.activation = nn.PReLU(num_parameters=self.num_units)\n",
        "        \n",
        "    def forward(self, x, h_prev):\n",
        "        \"\"\"\n",
        "        This method computes h_next(x, h_prev) and log P(x_next | h_next)\n",
        "        We'll call it repeatedly to produce the whole sequence.\n",
        "        \n",
        "        :param x: batch of character ids, containing vector of int64\n",
        "        :param h_prev: previous rnn hidden states, containing matrix [batch, rnn_num_units] of float32\n",
        "        \"\"\"\n",
        "\n",
        "        x_emb = self.embedding(x)\n",
        "        x_and_h = torch.cat([x_emb, h_prev], dim=-1)\n",
        "        h_next = self.rnn_update(x_and_h)\n",
        "        \n",
        "        h_next = self.activation(h_next)\n",
        "        logits = self.rnn_to_logits(h_next)\n",
        "        \n",
        "        return h_next, F.log_softmax(logits, -1)\n",
        "    \n",
        "    def initial_state(self, batch_size):\n",
        "        return torch.randn(batch_size, self.num_units, requires_grad=True).to(device)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znIkD3xirUA9"
      },
      "source": [
        "def to_matrix(tok_to_id, text, samples_num=5000, batch_len=300):\n",
        "    \n",
        "    return torch.tensor([[tok_to_id[tok] for tok in text[start:start+batch_len]]\n",
        "            for start in torch.randint(0, len(text) - batch_len, (samples_num,))]).to(device)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSKXco7ZrcyZ"
      },
      "source": [
        "def rnn_loop(char_rnn, batch_ix):\n",
        "    \"\"\"\n",
        "    Computes log P(next_character) for all time-steps in names_ix\n",
        "    :param names_ix: an int32 matrix of shape [batch, time], output of to_matrix(names)\n",
        "    \"\"\"\n",
        "    batch_size, max_length = batch_ix.size()\n",
        "    hid_state = char_rnn.initial_state(batch_size)\n",
        "    logprobs = []\n",
        "\n",
        "    for x_t in batch_ix.transpose(0,1):\n",
        "        hid_state, logp_next = char_rnn(x_t, hid_state)  # <-- here we call your one-step code\n",
        "        logprobs.append(logp_next)\n",
        "        \n",
        "    return torch.stack(logprobs, dim=1)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hy_cvlAYsEsq"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LC1woNWXreNa"
      },
      "source": [
        "batch_size = 200\n",
        "model = RNN()\n",
        "dataloader = DataLoader(to_matrix(token_to_idx, text), batch_size=batch_size, shuffle=True)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=2e-3, weight_decay=1e-3)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.7)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiVZBxF6sYb1"
      },
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=100):\n",
        "    \n",
        "    since = time.time()\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "    \n",
        "    losses = []\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for inputs in dataloader:\n",
        "            \n",
        "            inputs = inputs.to(device)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            logp_seq = rnn_loop(model, inputs)\n",
        "            #predictions_logp = logp_seq[:, :-1]\n",
        "            #actual_next_tokens = inputs[:, 1:]\n",
        "\n",
        "            logp_next = torch.gather(logp_seq[:, :-1], dim=2, index=inputs[:, 1:][:,:,None])\n",
        "\n",
        "            loss = -logp_next.mean()\n",
        "            loss.backward()\n",
        "            \n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            running_loss += loss\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        epoch_loss = running_loss / len(dataloader)\n",
        "        losses.append(epoch_loss)\n",
        "        clear_output(True)\n",
        "        plt.plot(losses, label='current loss: {:.2}'.format(epoch_loss))\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    \n",
        "    return model, losses"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyubjB6v_aVj"
      },
      "source": [
        "Plot the loss function (axis X: number of epochs, axis Y: loss function)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "d720-SMa_aVj",
        "outputId": "103d4e66-3eb9-47cc-9fcd-451703355311"
      },
      "source": [
        "# Your plot code here\n",
        "model, losses = train_model(model, criterion, optimizer, scheduler)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Training complete in 44m 13s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a67t__0h_aVj"
      },
      "source": [
        "def generate_sample(char_rnn, seed_phrase='hello my friends, ', max_length=500, temperature=1.0):\n",
        "    '''\n",
        "    The function generates text given a phrase of length at least SEQ_LENGTH.\n",
        "    :param seed_phrase: prefix characters. The RNN is asked to continue the phrase\n",
        "    :param max_length: maximum output length, including seed_phrase\n",
        "    :param temperature: coefficient for sampling.  higher temperature produces more chaotic outputs,\n",
        "                        smaller temperature converges to the single most likely output\n",
        "    '''\n",
        "    \n",
        "    x_sequence = [token_to_idx[token] for token in seed_phrase]\n",
        "    x_sequence = torch.tensor([x_sequence], dtype=torch.int64, device=device)\n",
        "    hid_state = char_rnn.initial_state(batch_size=1)\n",
        "    char_rnn.eval()\n",
        "    \n",
        "    for i in range(len(seed_phrase) - 1):\n",
        "        hid_state, _ = char_rnn(x_sequence[:, i], hid_state)\n",
        "    \n",
        "    for _ in range(max_length - len(seed_phrase)):\n",
        "        hid_state, logp_next = char_rnn(x_sequence[:, -1], hid_state)\n",
        "        p_next = F.softmax(logp_next / temperature, dim=-1).data.cpu().numpy()[0]\n",
        "        \n",
        "        next_ix = np.random.choice(len(token_to_idx), p=p_next)\n",
        "        next_ix = torch.tensor([[next_ix]], dtype=torch.int64, device=device)\n",
        "        x_sequence = torch.cat([x_sequence, next_ix], dim=1)\n",
        "        \n",
        "    return ''.join([tokens[ix] for ix in x_sequence.data.cpu().numpy()[0]])"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpyDg6-k4AwZ",
        "outputId": "54bda5a1-3bac-4d08-849f-a55f203a3624"
      },
      "source": [
        "print(generate_sample(model, seed_phrase='hello my friends, i want to say that', \n",
        "                      max_length=500, temperature=0.5))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hello my friends, i want to say that the truth's lose, then happy i show, when the give the self thou days are of diest the merit the may,\n",
            "    that thou best be the time more love's first, and shall not farther than your was not spend.\n",
            "  now sing thou art the strangely be the sweet that shall be that so it suberre that thy self as ext'st thou the comment, and love and thee,\n",
            "  though the stall where where the the will be grow\n",
            "  to his abling pend,\n",
            "  and so should leven the leaves in thy self is b\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgB2aI61_aVk",
        "outputId": "e2a42e16-efae-46c1-e507-1561be111628"
      },
      "source": [
        "# An example of generated text.\n",
        "# print(generate_text(length=500, temperature=0.2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hide my will in thine?\n",
            "  shall will in of the simend that in my sime the seave the seave the sorll the soren the sange the seall seares and and the fart the wirl the seall the songh whing that thou hall will thoun the soond beare the with that sare the simest me the fart the wirl the songre the with thy seart so for shat so for do the dost the sing the sing the sing the soond canding the sack and the farling the wirl of sore sich and that with the seare the seall so fort the with the past the wirl the simen the wirl the sores the sare\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0m1JhcD_aVm"
      },
      "source": [
        "### More poetic model\n",
        "\n",
        "Let's use LSTM instead of vanilla RNN and compare the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qy5Ti5Cg_aVn"
      },
      "source": [
        "Plot the loss function of the number of epochs. Does the final loss become better?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "fElnFEry_aVn"
      },
      "source": [
        "# Your beautiful code here\n",
        "class LSTM(nn.Module):\n",
        "    \n",
        "    def __init__(self, num_tokens=len(token_to_idx), embedding_size=100, rnn_num_units=200):\n",
        "        super(self.__class__, self).__init__()\n",
        "        self.num_units = rnn_num_units\n",
        "        self.embedding = nn.Embedding(num_tokens, embedding_size)\n",
        "        \n",
        "        self.lstm = nn.LSTMCell(embedding_size, rnn_num_units)\n",
        "        self.fc = nn.Linear(in_features=rnn_num_units, out_features=len(token_to_idx))\n",
        "        \n",
        "    def forward(self, x, h_prev, c_prev):\n",
        "        \"\"\"\n",
        "        This method computes h_next(x, h_prev) and log P(x_next | h_next)\n",
        "        We'll call it repeatedly to produce the whole sequence.\n",
        "        \n",
        "        :param x: batch of character ids, containing vector of int64\n",
        "        :param h_prev: previous rnn hidden states, containing matrix [batch, rnn_num_units] of float32\n",
        "        \"\"\"\n",
        "        x_emb = self.embedding(x)\n",
        "        h, c = self.lstm(x_emb, (h_prev, c_prev))\n",
        "        \n",
        "        output = self.fc(h)\n",
        "        \n",
        "        return h, c, F.log_softmax(output, -1)\n",
        "    \n",
        "    def initial_state(self, batch_size):\n",
        "        return torch.randn(batch_size, self.num_units, requires_grad=True).to(device), \\\n",
        "               torch.randn(batch_size, self.num_units, requires_grad=True).to(device)"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPOgFQkwuCVk"
      },
      "source": [
        "def lstm_loop(model, batch_ix):\n",
        "    \"\"\"\n",
        "    Computes log P(next_character) for all time-steps in names_ix\n",
        "    :param names_ix: an int32 matrix of shape [batch, time], output of to_matrix(names)\n",
        "    \"\"\"\n",
        "    batch_size, max_length = batch_ix.size()\n",
        "    hid_state, cell_state = model.initial_state(batch_size)\n",
        "    logprobs = []\n",
        "\n",
        "    for x_t in batch_ix.transpose(0, 1):\n",
        "        hid_state, cell_state, logp_next = model(x_t, hid_state, cell_state)  # <-- here we call your one-step code\n",
        "        logprobs.append(logp_next)\n",
        "        \n",
        "    return torch.stack(logprobs, dim=1)"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8Q8HyybuHWl"
      },
      "source": [
        "model = LSTM()\n",
        "dataloader = DataLoader(to_matrix(token_to_idx, text), batch_size=batch_size, shuffle=True)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=2e-1, weight_decay=1e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkpaPh6ruKr3"
      },
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=50):\n",
        "    \n",
        "    since = time.time()\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "    \n",
        "    losses = []\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for inputs in dataloader:\n",
        "            \n",
        "            inputs = inputs.to(device)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            logp_seq = lstm_loop(model, inputs)\n",
        "            predictions_logp = logp_seq[:, :-1]\n",
        "            actual_next_tokens = inputs[:, 1:]\n",
        "\n",
        "            logp_next = torch.gather(predictions_logp, dim=2, index=actual_next_tokens[:,:,None])\n",
        "\n",
        "            loss = -logp_next.mean()\n",
        "            loss.backward()\n",
        "            \n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            running_loss += loss\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        epoch_loss = running_loss / len(dataloader)\n",
        "        losses.append(epoch_loss)\n",
        "        clear_output(True)\n",
        "        plt.plot(losses, label='current loss: {:.2}'.format(epoch_loss))\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    \n",
        "    return model, losses"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "p7GLbQuvuL3z",
        "outputId": "3af9d2f1-c3ba-4e51-ec0f-70a47c6d2985"
      },
      "source": [
        "model, losses = train_model(model, criterion, optimizer, scheduler)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-89-0415dba0475a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-88-3c959b62ee14>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlogp_next\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNBETXvz_aVn"
      },
      "source": [
        "Generate text using the trained net with different `temperature` parameter: `[0.1, 0.2, 0.5, 1.0, 2.0]`.\n",
        "\n",
        "Evaluate the results visually, try to interpret them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "bj1_jRDu_aVn"
      },
      "source": [
        "# Text generation with different temperature values here\n",
        "def generate_text(model, init=' Hide my will', length=256, temperature=1.0):\n",
        "\n",
        "    x_sequence = [token_to_idx[token] for token in init]\n",
        "    x_sequence = torch.tensor([x_sequence], dtype=torch.int64, device=device)\n",
        "    hid_state, cell_state = model.initial_state(batch_size=1)\n",
        "    model.eval()\n",
        "    \n",
        "    for i in range(len(init) - 1):\n",
        "        hid_state, cell_state, _ = model(x_sequence[:, i], hid_state, cell_state)\n",
        "    \n",
        "    for _ in range(length - len(init)):\n",
        "        hid_state, cell_state, logp_next = model(x_sequence[:, -1], hid_state, cell_state)\n",
        "        p_next = F.softmax(logp_next / temperature, dim=-1).data.cpu().numpy()[0]\n",
        "        \n",
        "        next_ix = np.random.choice(len(token_to_idx), p=p_next)\n",
        "        next_ix = torch.tensor([[next_ix]], dtype=torch.int64, device=device)\n",
        "        x_sequence = torch.cat([x_sequence, next_ix], dim=1)\n",
        "        \n",
        "    return ''.join([tokens[ix] for ix in x_sequence.data.cpu().numpy()[0]])"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WV_HXOCauaBH",
        "outputId": "38b9c7c2-87b0-4290-ed90-b1e8e3d8baa0"
      },
      "source": [
        "print(\"Generated texts:\")\n",
        "\n",
        "for temp in [0.1, 0.2, 0.5, 1.0, 2.0]:\n",
        "    print(generate_text(model, init='please, go to ', length=100, temperature=temp))\n",
        "    print(\"-\"*20)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generated texts:\n",
            "please, go to me, not forth where thou art so muse,\n",
            "  and shows not solen in the sun other part:\n",
            "   \n",
            "--------------------\n",
            "please, go to me groand;\n",
            "  and see that thou see'int one own worth to his sweet self to praise.\n",
            "\n",
            "  x\n",
            "--------------------\n",
            "please, go to with the spring,\n",
            "  when thou thine on thy beauty doth even\n",
            "  what his in thee hath tha\n",
            "--------------------\n",
            "please, go to make my leaves qoly.\n",
            "\n",
            "  xlave sweet love i was tme dead flame of self-love'st.\n",
            "\n",
            "  xix\n",
            "\n",
            "--------------------\n",
            "please, go to me.k dicin thy ygy spenfitgers would kzawhwarratq!\n",
            "  bake qucwing abvisinxxage; it pin\n",
            "--------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVLQpVSA_aVo"
      },
      "source": [
        "### Saving and loading models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZVz86Y__aVo"
      },
      "source": [
        "Save the model to the disk, then load it and generate text. Examples are available [here](https://pytorch.org/tutorials/beginner/saving_loading_models.html])."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIRAZE3YEQNV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWm9c1hJuiH7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5Lsy20w_aVp"
      },
      "source": [
        "### References\n",
        "1. <a href='http://karpathy.github.io/2015/05/21/rnn-effectiveness/'> Andrew Karpathy blog post about RNN. </a> \n",
        "There are several examples of genration: Shakespeare texts, Latex formulas, Linux Sourse Code and children names.\n",
        "2. <a href='https://github.com/karpathy/char-rnn'> Repo with char-rnn code </a>\n",
        "3. Cool repo with PyTorch examples: [link](https://github.com/spro/practical-pytorch`)"
      ]
    }
  ]
}